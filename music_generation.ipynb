{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecological-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "#library for understanding music\n",
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "standard-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function to read MIDI files\n",
    "def read_midi(file):\n",
    "    \n",
    "    print(\"Loading Music File:\",file)\n",
    "    \n",
    "    notes=[]\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    #parsing a midi file\n",
    "    midi = converter.parse(file)\n",
    "  \n",
    "    #grouping based on different instruments\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "\n",
    "    #Looping over all the instruments\n",
    "    for part in s2.parts:\n",
    "    \n",
    "        #select elements of only piano\n",
    "        if 'Piano' in str(part): \n",
    "        \n",
    "            notes_to_parse = part.recurse() \n",
    "      \n",
    "            #finding whether a particular element is note or a chord\n",
    "            for element in notes_to_parse:\n",
    "                \n",
    "                #note\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                \n",
    "                #chord\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return np.array(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "desirable-visiting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: C:/Users/julia/Downloads/deephouse/Jamie XX - Stranger In A Room (Bjorn Wolf Edit).mp3.mid\n"
     ]
    }
   ],
   "source": [
    "#for listing down the file names\n",
    "import os\n",
    "\n",
    "#Array Processing\n",
    "import numpy as np\n",
    "\n",
    "#specify the path\n",
    "path='C:/Users/julia/Downloads/deephouse/'\n",
    "\n",
    "#read all the filenames\n",
    "files=[i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
    "\n",
    "#reading each midi file\n",
    "notes_array = np.array([read_midi(path+i) for i in files],dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "simple-julian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "861\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#converting 2D array into 1D array\n",
    "notes_ = [element for note_ in notes_array for element in note_]\n",
    "\n",
    "#No. of unique notes\n",
    "unique_notes = list(set(notes_))\n",
    "print(len(unique_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "double-blocking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([823.,  26.,   4.,   2.,   2.,   1.,   0.,   1.,   1.,   1.]),\n",
       " array([  1. ,  72.2, 143.4, 214.6, 285.8, 357. , 428.2, 499.4, 570.6,\n",
       "        641.8, 713. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 302,
       "width": 319
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#importing library\n",
    "from collections import Counter\n",
    "\n",
    "#computing frequency of each note\n",
    "freq = dict(Counter(notes_))\n",
    "\n",
    "#library for visualiation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#consider only the frequencies\n",
    "no=[count for _,count in freq.items()]\n",
    "\n",
    "#set the figure size\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "#plot\n",
    "plt.hist(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sonic-legislature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "frequent_notes = [note_ for note_, count in freq.items() if count>=50]\n",
    "print(len(frequent_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "level-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_music=[]\n",
    "\n",
    "for notes in notes_array:\n",
    "    temp=[]\n",
    "    for note_ in notes:\n",
    "        if note_ in frequent_notes:\n",
    "            temp.append(note_)            \n",
    "    new_music.append(temp)\n",
    "    \n",
    "new_music = np.array(new_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "social-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_timesteps = 32\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for note_ in new_music:\n",
    "    for i in range(0, len(note_) - no_of_timesteps, 1):\n",
    "        \n",
    "        #preparing input and output sequences\n",
    "        input_ = note_[i:i + no_of_timesteps]\n",
    "        output = note_[i + no_of_timesteps]\n",
    "        \n",
    "        x.append(input_)\n",
    "        y.append(output)\n",
    "        \n",
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fleet-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_x = list(set(x.ravel()))\n",
    "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "decreased-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing input sequences\n",
    "x_seq=[]\n",
    "for i in x:\n",
    "    temp=[]\n",
    "    for j in i:\n",
    "        #assigning unique integer to every note\n",
    "        temp.append(x_note_to_int[j])\n",
    "    x_seq.append(temp)\n",
    "    \n",
    "x_seq = np.array(x_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "concrete-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_y = list(set(y))\n",
    "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
    "y_seq=np.array([y_note_to_int[i] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "typical-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "satisfactory-render",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 32, 100)           5200      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 32, 64)            19264     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 16, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16, 128)           24704     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 8, 256)            98560     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 52)                13364     \n",
      "=================================================================\n",
      "Total params: 226,884\n",
      "Trainable params: 226,884\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "    \n",
    "#embedding layer\n",
    "model.add(Embedding(len(unique_x), 100, input_length=32,trainable=True)) \n",
    "\n",
    "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "    \n",
    "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "          \n",
    "#model.add(Conv1D(256,5,activation='relu'))    \n",
    "model.add(GlobalMaxPool1D())\n",
    "    \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(unique_y), activation='softmax'))\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "stuffed-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc=ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "handled-encyclopedia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "47/47 [==============================] - 4s 72ms/step - loss: 3.7628 - val_loss: 3.6584\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.65838, saving model to best_model.h5\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 3.5527 - val_loss: 3.6104\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.65838 to 3.61038, saving model to best_model.h5\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 3s 58ms/step - loss: 3.4994 - val_loss: 3.5442\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.61038 to 3.54421, saving model to best_model.h5\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 3.4396 - val_loss: 3.4902\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.54421 to 3.49021, saving model to best_model.h5\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 3s 61ms/step - loss: 3.4184 - val_loss: 3.4502\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.49021 to 3.45018, saving model to best_model.h5\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 3s 69ms/step - loss: 3.3306 - val_loss: 3.4138\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.45018 to 3.41379, saving model to best_model.h5\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 4s 86ms/step - loss: 3.2666 - val_loss: 3.3444\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.41379 to 3.34439, saving model to best_model.h5\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 4s 82ms/step - loss: 3.2113 - val_loss: 3.3230\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.34439 to 3.32304, saving model to best_model.h5\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 3s 73ms/step - loss: 3.1526 - val_loss: 3.3081\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.32304 to 3.30815, saving model to best_model.h5\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 4s 91ms/step - loss: 3.1400 - val_loss: 3.2927\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.30815 to 3.29273, saving model to best_model.h5\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 4s 76ms/step - loss: 3.0919 - val_loss: 3.2786\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.29273 to 3.27862, saving model to best_model.h5\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 3s 72ms/step - loss: 3.0679 - val_loss: 3.2611\n",
      "\n",
      "Epoch 00012: val_loss improved from 3.27862 to 3.26112, saving model to best_model.h5\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 3s 72ms/step - loss: 3.0271 - val_loss: 3.2549\n",
      "\n",
      "Epoch 00013: val_loss improved from 3.26112 to 3.25492, saving model to best_model.h5\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 4s 75ms/step - loss: 2.9845 - val_loss: 3.2526\n",
      "\n",
      "Epoch 00014: val_loss improved from 3.25492 to 3.25255, saving model to best_model.h5\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 4s 78ms/step - loss: 2.9522 - val_loss: 3.2294\n",
      "\n",
      "Epoch 00015: val_loss improved from 3.25255 to 3.22936, saving model to best_model.h5\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 4s 86ms/step - loss: 2.9278 - val_loss: 3.2322\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.22936\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 3s 69ms/step - loss: 2.9113 - val_loss: 3.2534\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.22936\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 4s 89ms/step - loss: 2.8534 - val_loss: 3.2458\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.22936\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 5s 107ms/step - loss: 2.8525 - val_loss: 3.2349\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.22936\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 4s 89ms/step - loss: 2.8232 - val_loss: 3.2284\n",
      "\n",
      "Epoch 00020: val_loss improved from 3.22936 to 3.22844, saving model to best_model.h5\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 4s 92ms/step - loss: 2.7833 - val_loss: 3.2349\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.22844\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 4s 94ms/step - loss: 2.7356 - val_loss: 3.2476\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.22844\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 4s 94ms/step - loss: 2.7541 - val_loss: 3.2402\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.22844\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 4s 91ms/step - loss: 2.6738 - val_loss: 3.2525\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.22844\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 4s 88ms/step - loss: 2.6435 - val_loss: 3.2450\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.22844\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 5s 97ms/step - loss: 2.6109 - val_loss: 3.2725\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.22844\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 4s 92ms/step - loss: 2.5940 - val_loss: 3.2777\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.22844\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 4s 91ms/step - loss: 2.5495 - val_loss: 3.3002\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.22844\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 4s 91ms/step - loss: 2.5467 - val_loss: 3.2858\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.22844\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 5s 96ms/step - loss: 2.4867 - val_loss: 3.3237\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.22844\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 4s 91ms/step - loss: 2.4857 - val_loss: 3.3389\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.22844\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 4s 92ms/step - loss: 2.4141 - val_loss: 3.3424\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.22844\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 4s 93ms/step - loss: 2.4014 - val_loss: 3.3491\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.22844\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 4s 95ms/step - loss: 2.3763 - val_loss: 3.3649\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.22844\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 4s 95ms/step - loss: 2.2992 - val_loss: 3.4161\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.22844\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 4s 91ms/step - loss: 2.3185 - val_loss: 3.4398\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.22844\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 4s 96ms/step - loss: 2.2700 - val_loss: 3.4360\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.22844\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 4s 93ms/step - loss: 2.2291 - val_loss: 3.4330\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.22844\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 4s 91ms/step - loss: 2.2146 - val_loss: 3.4861\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.22844\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 4s 91ms/step - loss: 2.1743 - val_loss: 3.4670\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3.22844\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 4s 96ms/step - loss: 2.1177 - val_loss: 3.5068\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 3.22844\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 4s 92ms/step - loss: 2.1091 - val_loss: 3.5041\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 3.22844\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 4s 90ms/step - loss: 2.0830 - val_loss: 3.5272\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 3.22844\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 4s 93ms/step - loss: 2.0326 - val_loss: 3.5578\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3.22844\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 5s 98ms/step - loss: 1.9938 - val_loss: 3.5452\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 3.22844\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 4s 89ms/step - loss: 1.9979 - val_loss: 3.6001\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 3.22844\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 4s 93ms/step - loss: 1.9942 - val_loss: 3.6165\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 3.22844\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 4s 95ms/step - loss: 1.9622 - val_loss: 3.6350\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 3.22844\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 4s 93ms/step - loss: 1.9102 - val_loss: 3.6644\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 3.22844\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 4s 90ms/step - loss: 1.8832 - val_loss: 3.6786\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3.22844\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50, validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "little-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading best model\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "expected-alarm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33, 20, 20, 33, 33, 20, 20, 33, 15, 33, 33, 14, 14, 14, 14, 20, 20, 33, 14, 33, 33, 33, 14, 20, 20, 20, 20, 33, 33, 33, 33, 20, 20, 20, 33, 33, 20, 33, 14, 33, 33, 33, 14, 14, 20, 20, 20, 33, 33, 33, 33, 33, 20, 20, 20, 20, 20, 33, 33, 33, 33, 33, 20, 20, 33, 20, 20, 33, 33, 33, 33, 33, 33, 20, 20, 20, 20, 20, 20, 33, 33, 33, 33, 33, 20, 20, 20, 20, 20, 33, 33, 15, 15, 33, 20, 33, 20, 20, 20, 33]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "ind = np.random.randint(0,len(x_val)-1)\n",
    "\n",
    "random_music = x_val[ind]\n",
    "\n",
    "predictions=[]\n",
    "for i in range(100):\n",
    "\n",
    "    random_music = random_music.reshape(1,no_of_timesteps)\n",
    "\n",
    "    prob  = model.predict(random_music)[0]\n",
    "    y_pred= np.argmax(prob,axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "settled-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
    "predicted_notes = [x_int_to_note[i] for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "spatial-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output):\n",
    "   \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            \n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 1\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='music.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "known-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_midi(predicted_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-parcel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
